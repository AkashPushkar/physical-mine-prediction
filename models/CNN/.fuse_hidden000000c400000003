import torch
import torch.nn as nn
import torch.nn.functional as F 
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

import numpy as np 
import pandas as pd

from sqlalchemy import create_engine
from pdb import set_trace as st
import os

# from ../../utils import input3
import input3

# Reading the data

conn = input3.connectToServer()

a = input3.data1(conn)

traindataloader = DataLoader()




# Defining architecture
class Net(nn.Module):
	def __init__(self):
		super(Net, self).__init__()

		self.conv1 = nn.Conv2d(23, 48, 5)
		self.conv2 = nn.Conv2d(48, 96, 5)

		self.fc1 = nn.Linear(13*13*96, 1600)
		self.fc2 = nn.Linear(1600, 400)
		self.fc3 = nn.Linear(400, 2)

	def forward(self, x):
		x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))
		x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))
		x = x.view(-1, self.num_flat_features(x))
		x = F.relu(self.fc1(x))
		x = F.relu(self.fc2(x))
		x = self.fc3(x)
		return x

	def num_flat_features(self, x):
		size = x.size()[1:]
		num_features = 1
		for s in size:
			num_features *= s
		return num_features

net = Net()
# print (net)

# params = list(net.parameters())
# print(len(params))
# for i in params:
# 	print(i.size())



# Defining the loss function and optimizer

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum = 0.9)


# training of the network
numberEpoch = 2
trainError = []
testError = []
batchNumber = []



for epoch in range(numberEpoch):

	running_loss = 0
	for i_batch, batch_sampled in enumerate(traindataloader):
		# inputs
		inputs = batch_sampled['input']
		label = batch_sampled['class']
		
		# parameters
		optimizer.zero_grad()

		# forward + backward + optimize
		out = net(inputs)
		loss = criterion(outputs, labels)
		loss.backward()
		optimizer.step()

		# printing stat
		running_loss += loss.item()
		if i_batch % 1000 == 0:
			trainError.append(running_loss/1000)
			batchNumber.append(i_batch+1)
			print(i_batch)
			running_loss = 0

print('Training Finished')













